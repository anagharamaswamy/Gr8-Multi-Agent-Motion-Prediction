{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VisionTransformerLyft.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St4CsJfCCw5k",
        "outputId": "ab1e14f7-86f0-4c2c-f048-aad994cd70c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: l5kit in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from l5kit) (4.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from l5kit) (5.3.1)\n",
            "Requirement already satisfied: torchvision<1.0.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from l5kit) (0.12.0+cu113)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from l5kit) (7.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.4.1)\n",
            "Requirement already satisfied: ptable in /usr/local/lib/python3.7/dist-packages (from l5kit) (0.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from l5kit) (3.2.2)\n",
            "Requirement already satisfied: opencv-contrib-python-headless in /usr/local/lib/python3.7/dist-packages (from l5kit) (4.5.5.64)\n",
            "Requirement already satisfied: numpy~=1.19.0 in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from l5kit) (3.17.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from l5kit) (4.64.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from l5kit) (6.0)\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.7/dist-packages (from l5kit) (2.11.3)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from l5kit) (0.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from l5kit) (57.4.0)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.11.0+cu113)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from l5kit) (2.3.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from l5kit) (1.8.1.post1)\n",
            "Requirement already satisfied: transforms3d in /usr/local/lib/python3.7/dist-packages (from l5kit) (0.3.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from l5kit) (2.4.1)\n",
            "Requirement already satisfied: pymap3d in /usr/local/lib/python3.7/dist-packages (from l5kit) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->l5kit) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.6.0->l5kit) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.6.0->l5kit) (7.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->l5kit) (21.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->l5kit) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->l5kit) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->l5kit) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->l5kit) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->l5kit) (3.0.8)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->l5kit) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->l5kit) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->l5kit) (0.16.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (3.6.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (1.1.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (5.1.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (5.3.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->l5kit) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->l5kit) (5.3.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->l5kit) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->l5kit) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->l5kit) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->l5kit) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->l5kit) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->l5kit) (4.4.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->l5kit) (2.15.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->l5kit) (4.10.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->l5kit) (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->l5kit) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->l5kit) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->l5kit) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->l5kit) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->l5kit) (3.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets->l5kit) (0.2.5)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (0.13.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->l5kit) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->l5kit) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->l5kit) (0.7.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->l5kit) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->l5kit) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (5.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->l5kit) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->l5kit) (0.5.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.6.0->l5kit) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.6.0->l5kit) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.6.0->l5kit) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.6.0->l5kit) (3.0.4)\n",
            "Requirement already satisfied: numcodecs>=0.6.4 in /usr/local/lib/python3.7/dist-packages (from zarr->l5kit) (0.9.1)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.7/dist-packages (from zarr->l5kit) (0.17.3)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.7/dist-packages (from zarr->l5kit) (0.3.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install l5kit\n",
        "!pip install -U PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models.git\n",
        "!pip install --target=/kaggle/working pymap3d==2.1.0 -q\n",
        "!pip install --target=/kaggle/working strictyaml -q\n",
        "!pip install --target=/kaggle/working protobuf==3.12.2 -q\n",
        "!pip install --target=/kaggle/working transforms3d -q\n",
        "!pip install --target=/kaggle/working zarr -q\n",
        "!pip install --target=/kaggle/working ptable -q\n",
        "!pip install --no-dependencies --target=/kaggle/working l5kit==1.1.0 --upgrade -q\n",
        "!pip install pytorch-pfn-extras==0.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h8XqVO8C71K",
        "outputId": "e0ee160f-891c-4347-8ec5-75eb2157322d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/rwightman/pytorch-image-models.git\n",
            "  Cloning https://github.com/rwightman/pytorch-image-models.git to /tmp/pip-req-build-4umz9dye\n",
            "  Running command git clone -q https://github.com/rwightman/pytorch-image-models.git /tmp/pip-req-build-4umz9dye\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.6.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.6.1) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.6.1) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.6.1) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.6.1) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.6.1) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.6.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.6.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.6.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.6.1) (2.10)\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/pymap3d-2.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/pymap3d already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/strictyaml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/python_dateutil-2.8.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/strictyaml-1.6.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow-metadata 1.7.0 requires protobuf<4,>=3.13, but you have protobuf 3.12.2 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/protobuf-3.12.2-py3.7-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/setuptools-62.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/google already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/protobuf-3.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/transforms3d already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/transforms3d-0.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "l5kit 1.5.0 requires numpy~=1.19.0, but you have numpy 1.21.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/asciitree already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/numcodecs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/fasteners already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/zarr already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/zarr-2.11.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/numpy-1.21.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/numcodecs-0.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/asciitree-0.3.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/fasteners-0.17.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/PTable-0.9.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/prettytable already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /kaggle/working/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "Requirement already satisfied: pytorch-pfn-extras==0.3.1 in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pfn-extras==0.3.1) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-pfn-extras==0.3.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-pfn-extras==0.3.1) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "\n",
        "!pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "OKLHi6qQDNzD",
        "outputId": "6cb2e3a8-07fc-4b19-a6cc-0c6a52e813ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.1.2.30\n",
            "Uninstalling opencv-python-headless-4.1.2.30:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.1.2.30.dist-info/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/config-3.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/config.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.abi3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/gapi/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py2.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py3.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/mat_wrapper/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/misc/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/misc/version.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/utils/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/version.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.1.2.30\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Using cached opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.19.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4gjjEJPg7BD",
        "outputId": "147fd785-4de8-4764-dd3a-675f41f76701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLyTe0VxbfLv",
        "outputId": "cda51558-92dc-4612-bf53-061fdb1d8b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.kaggle/\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!echo '{\"username\":\"simarkareer\",\"key\":\"ff816530aeb5eda4d7ce160a471cbe14\"}' >> /root/.kaggle/kaggle.json\n",
        "!cat /root/.kaggle/kaggle.json\n",
        "!mkdir lyftdataset\n",
        "!cd lyftdataset\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!kaggle --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-L_S329hbMq",
        "outputId": "17a19cb9-df9c-49f1-cd99-6a9c31a99e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"username\":\"simarkareer\",\"key\":\"ff816530aeb5eda4d7ce160a471cbe14\"}\n",
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=db640b380b30e1705b297e5a3550e817944770db29a098cfcaa82ef0097b9eb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Kaggle API 1.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd lyftdataset\n",
        "!unzip -q /content/drive/MyDrive/Deep\\ Learning\\ Project/lyft-motion-prediction-autonomous-vehicles.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h2qu7t2gNir",
        "outputId": "04428103-6088-4dd6-c803-0392f80af28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'lyftdataset'\n",
            "/content/lyftdataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/lyft/l5kit/master/examples/agent_motion_prediction/agent_motion_config.yaml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE5lQv7jQxZY",
        "outputId": "557d4540-3df3-44f1-c5dc-4020aff491eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-28 19:01:45--  https://raw.githubusercontent.com/lyft/l5kit/master/examples/agent_motion_prediction/agent_motion_config.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2019 (2.0K) [text/plain]\n",
            "Saving to: ‘agent_motion_config.yaml’\n",
            "\n",
            "agent_motion_config 100%[===================>]   1.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-28 19:01:45 (29.8 MB/s) - ‘agent_motion_config.yaml’ saved [2019/2019]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from timm.models import vision_transformer\n",
        "import torch\n",
        "import l5kit, os\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import warnings;warnings.filterwarnings(\"ignore\")\n",
        "from l5kit.rasterization import build_rasterizer\n",
        "from l5kit.configs import load_config_data\n",
        "from l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR\n",
        "from tqdm import tqdm\n",
        "from l5kit.geometry import transform_points\n",
        "from collections import Counter\n",
        "from l5kit.data import PERCEPTION_LABELS\n",
        "from prettytable import PrettyTable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from l5kit.evaluation import write_pred_csv\n",
        "from l5kit.geometry import transform_points\n",
        "# cfg = load_config_data(\"../input/lyft-config-files/agent_motion_config.yaml\")\n",
        "cfg = load_config_data(\"/content/lyftdataset/agent_motion_config.yaml\")\n",
        "os.environ[\"L5KIT_DATA_FOLDER\"] = \"../input/lyft-motion-prediction-autonomous-vehicles\"\n",
        "model = vision_transformer.vit_small_patch32_224(pretrained=True)"
      ],
      "metadata": {
        "id": "Q1nbj9rLFI7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from l5kit.data import ChunkedDataset, LocalDataManager\n",
        "from l5kit.dataset import EgoDataset, AgentDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dm = LocalDataManager()\n",
        "test_config = cfg[\"test_data_loader\"]\n",
        "# test_config = cfg[\"train_data_loader\"]\n",
        "rasterizer = build_rasterizer(cfg, dm)\n",
        "test_chunked = ChunkedDataset(dm.require(test_config[\"key\"])).open()\n",
        "test_mask = np.load(f\"../input/lyft-motion-prediction-autonomous-vehicles/scenes/mask.npz\")[\"arr_0\"]\n",
        "test_dataset = AgentDataset(cfg, test_chunked, rasterizer, agents_mask=test_mask)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                              shuffle=test_config[\"shuffle\"],\n",
        "                              batch_size=test_config[\"batch_size\"],\n",
        "                              num_workers=test_config[\"num_workers\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "Lts54uzjFMca",
        "outputId": "add05564-6a25-442e-a8e1-46972af97c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9b5d1b6348c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# test_config = cfg[\"test_data_loader\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_data_loader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrasterizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rasterizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_chunked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunkedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../input/lyft-motion-prediction-autonomous-vehicles/scenes/mask.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"arr_0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/l5kit/rasterization/rasterizer_builder.py\u001b[0m in \u001b[0;36mbuild_rasterizer\u001b[0;34m(cfg, data_manager)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmap_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"py_semantic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"semantic_debug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0msemantic_map_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"semantic_map_key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mdataset_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_meta_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mworld_to_ecef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"world_to_ecef\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/l5kit/data/local_data_manager.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_path_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{key} is not present in local data folder {self.root_folder}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: semantic_map/semantic_map.pb is not present in local data folder ../input/lyft-motion-prediction-autonomous-vehicles"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from l5kit.data import ChunkedDataset, LocalDataManager\n",
        "from l5kit.dataset import EgoDataset, AgentDataset\n",
        "dm = LocalDataManager()\n",
        "train_cfg = cfg[\"train_data_loader\"]\n",
        "rasterizer = build_rasterizer(cfg, dm)\n",
        "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
        "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                              shuffle=train_cfg[\"shuffle\"],\n",
        "                              batch_size=train_cfg[\"batch_size\"],\n",
        "                              num_workers=train_cfg[\"num_workers\"])\n",
        "\n",
        "val_cfg = cfg[\"val_data_loader\"]\n",
        "val_zarr = ChunkedDataset(dm.require(val_cfg[\"key\"])).open()\n",
        "val_dataset = AgentDataset(cfg, val_zarr, rasterizer)\n",
        "val_dataset = torch.utils.data.Subset(val_dataset, range(0, 4000))\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                              shuffle=train_cfg[\"shuffle\"],\n",
        "                              batch_size=train_cfg[\"batch_size\"],\n",
        "                              num_workers=train_cfg[\"num_workers\"])"
      ],
      "metadata": {
        "id": "LKH_2gohDa6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "a22b2b57-f42d-42d8-fc03-4385edfbca47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-181b6b19c645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalDataManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_data_loader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrasterizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rasterizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_zarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunkedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgentDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_zarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrasterizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/l5kit/rasterization/rasterizer_builder.py\u001b[0m in \u001b[0;36mbuild_rasterizer\u001b[0;34m(cfg, data_manager)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmap_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"py_semantic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"semantic_debug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0msemantic_map_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"semantic_map_key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mdataset_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_meta_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mworld_to_ecef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"world_to_ecef\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/l5kit/data/local_data_manager.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_path_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{key} is not present in local data folder {self.root_folder}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: semantic_map/semantic_map.pb is not present in local data folder ../input/lyft-motion-prediction-autonomous-vehicles"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== INIT DATASET\n",
        "train_cfg = cfg[\"train_data_loader\"]\n",
        "rasterizer = build_rasterizer(cfg, dm)\n",
        "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
        "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], batch_size=train_cfg[\"batch_size\"], \n",
        "                             num_workers=train_cfg[\"num_workers\"])\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "id": "93KTFXnfjlPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LyftVIT(nn.Module):\n",
        "    \n",
        "    def __init__(self, vit: nn.Module):\n",
        "        super(LyftVIT, self).__init__()\n",
        "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
        "        num_in_channels = 3 + num_history_channels\n",
        "        self.vit = vit\n",
        "        num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n",
        "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
        "        self.vit.patch_embed.backbone.conv1[0] = nn.Conv2d(\n",
        "            num_in_channels,\n",
        "            32,\n",
        "            kernel_size=self.vit.patch_embed.backbone.conv1[0].kernel_size,\n",
        "            stride=self.vit.patch_embed.backbone.conv1[0].stride,\n",
        "            padding=self.vit.patch_embed.backbone.conv1[0].padding,\n",
        "            bias=False,\n",
        "        )\n",
        "        \n",
        "        \n",
        "        self.num_preds = num_targets * 3\n",
        "        self.num_modes = 3\n",
        "        \n",
        "        self.logit = nn.Linear(1000, out_features=self.num_preds + self.num_modes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.vit(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.logit(x)\n",
        "        bs, _ = x.shape\n",
        "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
        "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
        "        assert confidences.shape == (bs, self.num_modes)\n",
        "        confidences = torch.softmax(confidences, dim=1)\n",
        "        return pred, confidences"
      ],
      "metadata": {
        "id": "Y-ZI9BlcDf67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LyftVIT(model)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss(reduction=\"none\")"
      ],
      "metadata": {
        "id": "G4d0W95_EB6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x, y = batch[\"image\"].to(device), batch[\"target_positions\"].to(device)\n",
        "    avails = batch[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
        "    y_pred, conf = model(x)\n",
        "    loss = pytorch_neg_multi_log_likelihood_batch(y, y_pred, conf, avails[:, :, 0])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_step)\n",
        "\n",
        "def validation_step(image, target_positions, **kwargs):\n",
        "    x, y = image.to(device), target_positions.to(device)\n",
        "    y_pred = model(x)\n",
        "    return y_pred, y"
      ],
      "metadata": {
        "id": "ea6uTC4vEYsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_evaluator = E.Evaluator(\n",
        "    val_dataloader,\n",
        "    model,\n",
        "    progress_bar=False,\n",
        "    eval_func=validation_step,\n",
        ")\n",
        "\n",
        "log_trigger = (1000, \"iteration\")\n",
        "log_report = E.LogReport(trigger=log_trigger)\n",
        "extensions = [\n",
        "    log_report,  # Save `log` to file\n",
        "    valid_evaluator,\n",
        "    # E.FailOnNonNumber()  # Stop training when nan is detected.\n",
        "    E.ProgressBarNotebook(update_interval=100),  # Show progress bar during training\n",
        "    E.PrintReportNotebook(),  # Show \"log\" on jupyter notebook  \n",
        "]"
      ],
      "metadata": {
        "id": "IVOoXYZFEb7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\"main\": model}\n",
        "optimizers = {\"main\": optimizer}\n",
        "manager = IgniteExtensionsManager(\n",
        "    trainer,\n",
        "    models,\n",
        "    optimizers,\n",
        "    7,\n",
        "    extensions=extensions,\n",
        "    out_dir=\"../working\",\n",
        ")\n",
        "manager.extend(E.snapshot_object(model, \"predictor.pt\"),\n",
        "               trigger=(50, \"iteration\")) "
      ],
      "metadata": {
        "id": "biUCPY-SEeYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manager.iteration = 0\n",
        "manager._iters_per_epoch = len(train_dataloader)\n",
        "trainer.run(train_dataloader, max_epochs=7)"
      ],
      "metadata": {
        "id": "6YIkh-hwEfOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.vit.patch_embed.backbone.conv1[0] = nn.Conv2d(\n",
        "            5,\n",
        "            32,\n",
        "            kernel_size=model.vit.patch_embed.backbone.conv1[0].kernel_size,\n",
        "            stride=model.vit.patch_embed.backbone.conv1[0].stride,\n",
        "            padding=model.vit.patch_embed.backbone.conv1[0].padding,\n",
        "            bias=False,\n",
        "        )\n",
        "model.load_state_dict(torch.load('../input/lyft-vision-transformer-training/predictor.pt'))\n",
        "model.vit.patch_embed.backbone.conv1[0] = nn.Conv2d(\n",
        "            25,\n",
        "            32,\n",
        "            kernel_size=model.vit.patch_embed.backbone.conv1[0].kernel_size,\n",
        "            stride=model.vit.patch_embed.backbone.conv1[0].stride,\n",
        "            padding=model.vit.patch_embed.backbone.conv1[0].padding,\n",
        "            bias=False,\n",
        "        ).to(device)"
      ],
      "metadata": {
        "id": "C5rCGRm6EnS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "future_coords_offsets_pd = []\n",
        "timestamps = []\n",
        "agent_ids = []\n",
        "confs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    dataiter = tqdm(test_loader)\n",
        "    \n",
        "    for data in dataiter:\n",
        "\n",
        "        inputs = data[\"image\"].to(device)\n",
        "        target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
        "        targets = data[\"target_positions\"].to(device)\n",
        "        \n",
        "        outputs, conf = model(inputs)\n",
        "        preds = outputs.cpu().numpy()\n",
        "        conf = conf.cpu().numpy()\n",
        "        world_from_agents = data[\"world_from_agent\"].numpy()\n",
        "        centroids = data[\"centroid\"].numpy()\n",
        "        coords_offset = []\n",
        "        \n",
        "        # convert into world coordinates and compute offsets\n",
        "        for idx in range(len(preds)):\n",
        "            for mode in range(3):\n",
        "                preds[idx, mode, :, :] = transform_points(preds[idx, mode, :, :], world_from_agents[idx]) - centroids[idx][:2]\n",
        "    \n",
        "        future_coords_offsets_pd.append(preds.copy())\n",
        "        confs.append(conf.copy())\n",
        "        timestamps.append(data[\"timestamp\"].numpy().copy())\n",
        "        agent_ids.append(data[\"track_id\"].numpy().copy()) "
      ],
      "metadata": {
        "id": "3Z_e-5_iFbEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_pred_csv('submission.csv',\n",
        "               timestamps=np.concatenate(timestamps),\n",
        "               track_ids=np.concatenate(agent_ids),\n",
        "               coords=np.concatenate(future_coords_offsets_pd),\n",
        "              confs=np.concatenate(confs))"
      ],
      "metadata": {
        "id": "kfiOxX3iFddl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}